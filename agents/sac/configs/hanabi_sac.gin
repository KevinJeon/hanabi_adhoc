import sac_agent
import run_experiment

# This configures the DQN Agent.
AGENT_CLASS = @SACAgent
SACAgent.gamma = 0.99
SACAgent.update_horizon = 1
SACAgent.min_replay_history = 500 # agent steps
SACAgent.target_update_period = 500 # agent steps
SACAgent.epsilon_train = 0.0
SACAgent.epsilon_eval = 0.0
SACAgent.epsilon_decay_period = 1000 # agent steps
SACAgent.tf_device = '/gpu:0'  # '/cpu:*' use for non-GPU version



run_experiment.training_steps = 1
run_experiment.num_iterations = 1
run_experiment.checkpoint_every_n = 50
run_one_iteration.evaluate_every_n = 10

# Small Hanabi.
create_environment.game_type = 'Hanabi-Full-CardKnowledge'
create_environment.num_players = 2

create_agent.agent_type = 'SAC'
create_obs_stacker.history_size = 1

